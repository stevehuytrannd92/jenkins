// This annotation tells Jenkins to load the library you configured
@Library('my-shared-library') _ 



// Run a map of tasks with maxParallel at once
def runWithMaxParallel(tasks, maxParallel = 3) {
    def keys = tasks.keySet() as List
    def total = keys.size()

    for (int i = 0; i < total; i += maxParallel) {
        // üîë convert subList to real List so it's serializable
        def slice = new ArrayList(keys.subList(i, Math.min(i + maxParallel, total)))
        def batch = [:]
        slice.each { k -> batch[k] = tasks[k] }
        parallel batch
    }
}


pipeline {
    agent any
    tools {
        nodejs 'NODE_20'
    }

    parameters {
        booleanParam(
            name: 'FORCE_BUILD_ALL',
            defaultValue: false,
            description: 'Force build & deploy all repos, even if no new changes'
        )
        booleanParam(
            name: 'REMOVE_ALL_NGINX',
            defaultValue: false,
            description: 'Force remove all nginx on build and replace enable sites only'
        )
        string(
            name: 'MAX_PARALLEL',
            defaultValue: '4',
            description: 'Maximum number of tasks to run in parallel'
        )

    }

    options {
        disableConcurrentBuilds()   // üö´ no concurrent runs
        buildDiscarder(logRotator(numToKeepStr: '100')) // optional cleanup
        // timeout(time: 60, unit: 'MINUTES')            // optional safety
    }


    triggers {
        cron('0,10,20,30,40,50 * * * *')
    }


    stages {
        stage('Clear redis') {
            steps {
                script {
                    try {
                        redisState.clearAll()
                    } catch (Exception e) {
                        echo "redisState not found: ${e}"
                    }
                }
            }
        }



        stage('Load Script') {
            steps {
                script {
                    repos = load 'repos.groovy'
                    vpsInfos = load 'vps.groovy'

                }
            }
        }


        stage('Verify repo envs') {
            steps {
                script {
                    repos.each { repo ->
                        if (repo.envs.size() > 16) {
                            error "‚ùå Repo '${repo.folder}' has ${repo.envs.size()} envs, exceeds limit of 16."
                        }
                    }
                    echo "‚úÖ All repos have ‚â§ 16 envs."
                }
            }
        }

        stage('Verify Domains') {
            steps {
                script {
                    def domainMap = [:]
                    def duplicates = []

                    repos.each { repo ->
                        repo.envs.each { env ->
                            def domain = env.MAIN_DOMAIN
                                .replaceAll(/^https?:\/\//, '')   // remove protocol
                                .replaceAll(/\/$/, '')            // remove trailing slash
                                .toLowerCase()

                            if (domainMap.containsKey(domain)) {
                                duplicates << [
                                    domain: domain,
                                    repo1: domainMap[domain],
                                    repo2: "${repo.folder}:${env.name}"
                                ]
                            } else {
                                domainMap[domain] = "${repo.folder}:${env.name}"
                            }
                        }
                    }

                    if (duplicates) {
                        echo "‚ùå Found duplicate MAIN_DOMAIN(s):"
                        duplicates.each { d ->
                            echo " - ${d.domain} used in ${d.repo1} and ${d.repo2}"
                        }
                        error("Duplicate MAIN_DOMAIN detected, aborting build.")
                    } else {
                        echo "‚úÖ All MAIN_DOMAIN values are unique."
                    }
                }
            }
        }


        stage('Repos Pulls') {
            steps {
                script {
                    def parallelTasks = [:]
                    repos.each { repo ->
                        parallelTasks["Pull-${repo.folder}"] = {
                            dir(repo.folder) {
                                def vpsInfo = vpsInfos[repo.vpsRef]

                                if (!fileExists('.git')) {
                                    // First time clone
                                    checkout([
                                        $class: 'GitSCM',
                                        branches: [[name: "*/${repo.branch}"]],
                                        doGenerateSubmoduleConfigurations: false,
                                        userRemoteConfigs: [[
                                            url: repo.url,
                                            credentialsId: repo.credId
                                        ]],
                                        extensions: [
                                            // Optimize repo checkout
                                            [$class: 'CloneOption', depth: 1, noTags: true, shallow: true],
                                            [$class: 'PruneStaleBranch']
                                        ]
                                    ])
                                    redisState.addChangedRepo(repo.folder)
                                    // changedRepos << repo.folder
                                } else {
                                    def oldCommit = sh(script: "git rev-parse HEAD", returnStdout: true).trim()

                                    checkout([
                                        $class: 'GitSCM',
                                        branches: [[name: "*/${repo.branch}"]],
                                        doGenerateSubmoduleConfigurations: false,
                                        userRemoteConfigs: [[
                                            url: repo.url,
                                            credentialsId: repo.credId
                                        ]],
                                        extensions: [
                                            [$class: 'PruneStaleBranch'],
                                            [$class: 'CloneOption', depth: 1, noTags: true, shallow: true]
                                        ]
                                    ])

                                    def newCommit = sh(script: "git rev-parse HEAD", returnStdout: true).trim()

                                    if (oldCommit != newCommit) {
                                        echo "üîÑ Changes detected in ${repo.folder}: ${oldCommit} ‚Üí ${newCommit}"

                                        // changedRepos << repo.folder
                                        redisState.addChangedRepo(repo.folder)

                                    } else {
                                        echo "‚è≠Ô∏è No changes in ${repo.folder}"


                                    }
                                }

                            }

                        }
                    }

                    runWithMaxParallel(parallelTasks, params.MAX_PARALLEL.toInteger())  // üëà cap parallelism
                    
                    def changedRepos = redisState.getChangedRepos() as List

                    echo "Collected repos = ${changedRepos}"
                    if (!params.FORCE_BUILD_ALL && changedRepos.isEmpty()) {
                        echo "‚è≠Ô∏è No changes and FORCE_BUILD_ALL not set, stopping pipeline early."
                        return  // exits this stage, and since no later stages run ‚Üí SUCCESS
                    }
                }
            }
        }


        stage('Check Certificates') {
            when { expression { 
                def changedRepos = redisState.getChangedRepos() as List
                return params.FORCE_BUILD_ALL || !changedRepos.isEmpty() 
            } }

            steps {
                script {
                    def changedRepos = redisState.getChangedRepos() as List
                    def reposToCheck = params.FORCE_BUILD_ALL ? repos : repos.findAll { r -> changedRepos.contains(r.folder) }
                    def parallelTasks = [:]

                    reposToCheck.each { repo ->
                        def vpsInfo = vpsInfos[repo.vpsRef]
                        repo.envs.each { site ->
                            parallelTasks["check-${site.MAIN_DOMAIN}"] = {

                                def domain = commonUtils.extractDomain(site.MAIN_DOMAIN)

                                sshagent (credentials: [vpsInfo.vpsCredId]) {
                                    def exists = sh(
                                        script: """

                                            ssh -o StrictHostKeyChecking=no ${vpsInfo.vpsUser}@${vpsInfo.vpsHost} \
                                            "sudo test -f /etc/letsencrypt/live/${domain}/fullchain.pem && echo yes || echo no"
                                        """,
                                        returnStdout: true
                                    ).trim()

                                    if (exists == "no") {
                                        echo "‚ö†Ô∏è  Certificate missing for ${domain}"
                                        redisState.addMissingCert(domain)
                                    } else {
                                        echo "‚úÖ Certificate exists for ${domain}"
                                    }
                                }
                            }
                        }
                    }

                    runWithMaxParallel(parallelTasks, 3)  // üëà cap parallelism

                    if (redisState.getMissingCerts()) {
                        echo "‚ö†Ô∏è  Some certificates are missing: ${redisState.getMissingCerts()}"
                    } else {
                        echo "‚úÖ All certificates present"
                    }
                }
            }
        }


        stage('Build Projects') {
            steps {
                script {

                    def parallelSetups = [:]

                    repos.each { repo ->
                        parallelSetups["setup-${repo.folder}"] = {
                            if (!params.FORCE_BUILD_ALL && !redisState.isNewCommit(repo.folder)) {
                                echo "‚è≠Ô∏è Skipping setup for ${repo.folder}, no changes detected"
                                return
                            }
                            buildUtils.setupBuild(repo);
                        }
                    }

                    runWithMaxParallel(parallelSetups, 3)  // üëà cap parallelism

                    def parallelBuilds = [:]

                    repos.each { repo ->
                        repo.envs.eachWithIndex { envConf, idx ->
                            parallelBuilds["build-${envConf.name}"] = {
                                if (!params.FORCE_BUILD_ALL && !redisState.isNewCommit(repo.folder)) {
                                    echo "‚è≠Ô∏è Skipping setup for ${repo.folder}, no changes detected"
                                    return
                                }
                                buildUtils.build(repo, envConf);
                            }
                        }
                    }

                    runWithMaxParallel(parallelBuilds, params.MAX_PARALLEL.toInteger())  // üëà cap parallelism
                }
            }
        }

        stage('Deploy Outs to VPS') {
            steps {
                script {
                    def parallelTasks = [:]

                    repos.each { repo ->
                        if (!params.FORCE_BUILD_ALL && !redisState.isNewCommit(repo.folder)) {
                            echo "‚è≠Ô∏è Skipping build for ${repo.folder}, no changes detected"
                            return
                        }
                        repo.envs.eachWithIndex { envConf, idx ->
                            parallelTasks["deploy-${envConf.name}"] = {
                                deployUtils.deploy(repo, envConf, vpsInfos)
                            }
                        }
                    }

                    runWithMaxParallel(parallelTasks, 3)  // üëà cap parallelism

                }
            }
        }

        stage('Generate NGNIX config and deploy SSH') {
            steps {
                script {
                    def changedRepos = redisState.getChangedRepos()
                    def parallelTasks = [:]

                    if (!params.FORCE_BUILD_ALL && !changedRepos) {
                        echo "‚è≠Ô∏è Skipping nginx reload, no changes detected"
                        return
                    }
                    
                    if (params.REMOVE_ALL_NGINX ) {
                        echo "‚è≠Ô∏è Remove all sites before place new enable sites."
                        vpsInfos.values().each { vpsConf -> 
                            sshagent(credentials: [vpsConf.vpsCredId]) {
                                sh """
                                    ssh -o StrictHostKeyChecking=no ${vpsConf.vpsUser}@${vpsConf.vpsHost} "

                                        sudo rm -f /etc/nginx/sites-enabled/*
                                        
                                    "
                                """
                            }
                        }
                    }

                    repos.each { repo ->
                        repo.envs.each { envConf ->
                            parallelTasks["nginx-${envConf.name}"] = {
                                nginxUtils.generate(repo, envConf, vpsInfos )
                            }
                        }
                    }

                    runWithMaxParallel(parallelTasks, 3)  // üëà cap parallelism

                    vpsInfos.values().each { vpsConf -> 
                        sshagent(credentials: [vpsConf.vpsCredId]) {
                            sh """
                                ssh -o StrictHostKeyChecking=no ${vpsConf.vpsUser}@${vpsConf.vpsHost} "

                                    sudo nginx -t &&

                                    sudo systemctl reload nginx
                                "
                            """
                        }
                    }
                }
            }
        }
    }
}
